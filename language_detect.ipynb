{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMctOVU4cw+i/c440H4X00h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarthakbiswas97/design-llm-apps-exercises/blob/main/language_detect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from newspaper import Article\n",
        "\n",
        "url = 'https://timesofindia.indiatimes.com/india/save-your-lives-first-when-pakistan-army-commander-abandoned-post-during-operation-sindoor/articleshow/121364227.cms'\n",
        "article = Article(url)\n",
        "article.download()\n",
        "article.parse()\n",
        "\n",
        "print(\"Title:\", article.title)\n",
        "print(\"Text:\", article.text)\n",
        "# newspaper3k also has other useful attributes like article.authors, article.publish_date, etc.\n"
      ],
      "metadata": {
        "id": "Qpu7UqiNcidP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "C4 is an English language dataset, constructed by filtering out text from the raw dataset with less than 0.99 probability of being English according to langdetect. However, a lot of non-English data persists in this dataset. If you know a second language, then use the realnewslike subset of C4 to find instances in which text from that language appears. In what contexts do these non-English text fragments appear? Could an LLM learn these languages using these leftover fragments?"
      ],
      "metadata": {
        "id": "-RxGHojPgpe3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install --upgrade datasets\n",
        "!pip install langdetect\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Bri9jRTcfyhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from langdetect import detect_langs\n",
        "\n",
        "articles_to_process = 100\n",
        "confidence_threshold = 0.99\n",
        "\n",
        "try:\n",
        "  realnewslike = load_dataset(\"allenai/c4\", \"realnewslike\", split=\"train\", streaming=True)\n",
        "\n",
        "  for i, news_text in enumerate(realnewslike):\n",
        "    if i >= articles_to_process:\n",
        "      break\n",
        "\n",
        "    article_text = news_text.get(\"text\")\n",
        "\n",
        "    if not article_text or not article_text.strip():\n",
        "      continue\n",
        "\n",
        "    try:\n",
        "      detected_lang_list = detect_langs(article_text)\n",
        "\n",
        "      if not detected_lang_list:\n",
        "        continue\n",
        "\n",
        "      # Get the top language detection (most probable)\n",
        "      top_detection = detected_lang_list[0]\n",
        "      detected_lang_code = top_detection.lang  # e.g., 'en', 'es'\n",
        "      detected_lang_prob = top_detection.prob  # e.g., 0.999\n",
        "\n",
        "\n",
        "      # Condition 1: Detected language is English, but confidence is below the threshold\n",
        "      is_low_confidence_english = (detected_lang_code == 'en' and detected_lang_prob < confidence_threshold)\n",
        "\n",
        "      # Condition 2: Detected language is NOT English\n",
        "      is_not_english = (detected_lang_code != 'en')\n",
        "\n",
        "      if is_low_confidence_english or is_not_english:\n",
        "        print(\"Found low confidence English or non-English article\")\n",
        "        print(\"------------------------------------\")\n",
        "        if is_low_confidence_english:\n",
        "          print(f\"Type: Low Confidence English\")\n",
        "        else: # is_not_english\n",
        "          print(f\"Type: Detected as Non-English\")\n",
        "\n",
        "      print(f\"Detected Language: {detected_lang_code} (Probability: {detected_lang_prob:.4f})\")\n",
        "      print(\"Snippet (first 300 chars):\")\n",
        "      print(article_text[:300] + \"...\") # Print a snippet for context\n",
        "      print(\"------------------------------------\")\n",
        "\n",
        "    except Exception as e:\n",
        "      print(\"got error in language detection\", e)\n",
        "\n",
        "except Exception as e:\n",
        "  print(\"Got some error: \",e)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1AlYeg2DgEEz",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "hY37gxM4gkx3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a quality classifier using [fasttext](https://fasttext.cc/docs/en/support.html). Your positive examples can be drawn from Wikipedia, and the negative examples can be randomly drawn from the [unclean version of C4](https://huggingface.co/datasets/allenai/c4). Once trained, feed documents from the realnewslike subset of C4 to this classifier. Is this classifier able to do a good job?"
      ],
      "metadata": {
        "id": "iUkemMC4vyLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade fasttext\n",
        "%cd fastText\n",
        "!pip install .\n",
        "!pip install numpy==1.26.4\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xL6jTSVb3hru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting and preparing data\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/data/cooking.stackexchange.tar.gz && tar xvzf cooking.stackexchange.tar.gz\n",
        "!head cooking.stackexchange.txt\n",
        "!wc cooking.stackexchange.txt\n",
        "!head -n 12404 cooking.stackexchange.txt > cooking.train\n",
        "!tail -n 3000 cooking.stackexchange.txt > cooking.valid"
      ],
      "metadata": {
        "collapsed": true,
        "id": "jKDPElfKj4qA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Import and use fastText\n",
        "import fasttext\n",
        "import numpy as np # Import to check version\n",
        "\n",
        "print(f\"Using NumPy version: {np.__version__}\") # Should show 1.26.4\n",
        "\n",
        "# Train the model\n",
        "model = fasttext.train_supervised(input=\"cooking.train\")\n",
        "model.save_model(\"model_cooking.bin\")\n",
        "\n",
        "# Make predictions\n",
        "# Note: model.predict returns a tuple (labels, probabilities)\n",
        "# We usually care about the labels for simple prediction.\n",
        "predictions1 = model.predict(\"Which baking dish is best to bake a banana bread ?\")\n",
        "print(f\"Prediction 1: {predictions1}\")\n",
        "\n",
        "predictions2 = model.predict(\"Why not put knives in the dishwasher?\")\n",
        "print(f\"Prediction 2: {predictions2}\")\n",
        "\n",
        "# Test the model\n",
        "test_results = model.test(\"cooking.valid\")\n",
        "print(f\"Test results (N, P@1, R@1): {test_results}\")\n",
        "\n",
        "# To get precision and recall at k=5:\n",
        "test_results_k5 = model.test(\"cooking.valid\", k=5)\n",
        "print(f\"Test results (N, P@5, R@5): {test_results_k5}\")\n"
      ],
      "metadata": {
        "id": "Of36zVxjwyqs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}